{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1mRi1j2mRMMxCJDFAfPKITo70-HUyCOKx","authorship_tag":"ABX9TyMMFPqrERUtmIoWMMK8C1iX"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# **Nhận dạng ngôn ngữ ký hiệu Việt Nam (từ/cụm từ)**\n","*Hoàng Anh Hùng*\n","\n","Notebook này tiến hành huấn luyện model LSTM nhận dạng ngôn ngữ ký hiệu thời gian thực.\n","- **Dữ liệu**: 66 ký hiệu (66 cụm từ thường được sử dụng trong các trường hợp khẩn cấp hoặc trong các cơ sở y tế), mỗi ký hiệu có 30 videos thể hiện ký hiệu đó. Mỗi video trích xuất ra được 3 file (từ video gốc và 2 videos tăng cường) đặc trưng chứa thông tin vị trí tương đối của các điểm mốc trên 2 bàn tay, khoảng cách thay đổi của bàn tay qua từng frame và khoảng cách của mỗi bàn tay đến 2 vai.\n","- **Đầu ra**:\n","  - Model: `model/best_model.h5`\n","  - Các biểu đồ, thang điểm đánh giá kết quả nhận dạng."],"metadata":{"id":"PvDYsfR2Bag1"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"DTKgip8CuoQL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","# Verify TensorFlow and GPU\n","print(\"TensorFlow version:\", tf.__version__)\n","print(\"GPU available:\", tf.config.list_physical_devices('GPU'))\n","\n","# Paths\n","BASE_DIR = '/content/drive/MyDrive/Colab Notebooks/SLR_words'\n","DATA_DIR = '/content/word_features'\n","MODEL_DIR = os.path.join(BASE_DIR, 'model')\n","EVALUATION_DIR = os.path.join(BASE_DIR, 'evaluation')\n","METADATA_PATH = '/content/word_features/metadata.csv'\n","\n","# Create directories\n","os.makedirs(MODEL_DIR, exist_ok=True)\n","os.makedirs(EVALUATION_DIR, exist_ok=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iqMMxWKh4nPR","executionInfo":{"status":"ok","timestamp":1748164430959,"user_tz":-420,"elapsed":10370,"user":{"displayName":"Anh Hùng Hoàng","userId":"02884634796613907310"}},"outputId":"8daa2244-1e06-4f54-a263-9356b16bed28"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["TensorFlow version: 2.18.0\n","GPU available: []\n"]}]},{"cell_type":"code","source":["import zipfile\n","import pandas as pd\n","import os\n","\n","base_dir = \"/content/drive/MyDrive/Colab Notebooks/SLR_words\"\n","zip_path = os.path.join(base_dir, \"word_features.zip\")\n","extract_path = base_dir\n","\n","with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n","    zip_ref.extractall(extract_path)"],"metadata":{"id":"gpDO6tJcgpcA","executionInfo":{"status":"ok","timestamp":1748164511645,"user_tz":-420,"elapsed":76295,"user":{"displayName":"Anh Hùng Hoàng","userId":"02884634796613907310"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["!cp -r /content/drive/MyDrive/Colab\\ Notebooks/SLR_words/word_features /content/"],"metadata":{"id":"ODtlJCJP8WUJ","executionInfo":{"status":"ok","timestamp":1748164646825,"user_tz":-420,"elapsed":120512,"user":{"displayName":"Anh Hùng Hoàng","userId":"02884634796613907310"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["df = pd.read_csv(METADATA_PATH)\n","\n","df['feature_path'] = df['feature_path'].apply(\n","    lambda x: os.path.join(DATA_DIR, os.path.basename(x.replace('\\\\', '/')))\n",")\n","\n","df.to_csv(METADATA_PATH, index=False)\n","\n","print(df.head(3))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g3gaVyCUhUpD","executionInfo":{"status":"ok","timestamp":1748164664377,"user_tz":-420,"elapsed":104,"user":{"displayName":"Anh Hùng Hoàng","userId":"02884634796613907310"}},"outputId":"79a5f322-0efb-4044-b2f7-bf0b1134fca3"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["   video_id      label         type  \\\n","0         1  anh_huong     original   \n","1         1  anh_huong   rotated_15   \n","2         1  anh_huong  rotated_-15   \n","\n","                                     feature_path  \n","0     /content/word_features/video_1_original.npy  \n","1   /content/word_features/video_1_rotated_15.npy  \n","2  /content/word_features/video_1_rotated_-15.npy  \n"]}]},{"cell_type":"code","source":["def convert_feature_path(x):\n","    \"\"\"Convert feature_path to absolute path in DATA_DIR.\"\"\"\n","    x = x.replace('\\\\', '/')  # Replace backslashes with forward slashes\n","    filename = os.path.basename(x)  # Extract filename, e.g., video_4_original.npy\n","    return os.path.join(DATA_DIR, filename)\n","\n","def load_data(samples_per_label=30):\n","    \"\"\"Load data from metadata.csv, select 30*3 files per label.\"\"\"\n","    if not os.path.exists(METADATA_PATH):\n","        raise FileNotFoundError(f\"Metadata file not found: {METADATA_PATH}\")\n","\n","    metadata = pd.read_csv(METADATA_PATH)\n","    # Update feature_path to absolute path\n","    metadata['feature_path'] = metadata['feature_path'].apply(convert_feature_path)\n","    X, y = [], []\n","    count = 0\n","\n","    # Group by label\n","    labels = metadata['label'].unique()\n","    print(f\"Found {len(labels)} labels: {labels}\")\n","\n","    for label in labels:\n","        label_data = metadata[metadata['label'] == label]\n","        video_ids = label_data['video_id'].unique()\n","        selected_vids = np.random.choice(video_ids, size=min(samples_per_label, len(video_ids)), replace=False)\n","\n","        for vid in selected_vids:\n","            for vid_type in ['original', 'rotated_15', 'rotated_-15']:\n","                vid_data = label_data[(label_data['video_id'] == vid) & (label_data['type'] == vid_type)]\n","                if vid_data.empty:\n","                    print(f\"Missing {vid_type} for video_id {vid}, label {label}\")\n","                    continue\n","                feature_path = vid_data['feature_path'].iloc[0]\n","                features = np.load(feature_path)\n","                if features.shape == (30, 132):  # Check for 132-dimensional features\n","                    X.append(features)\n","                    y.append(label)\n","                    count += 1\n","                    if count % 100 == 0:\n","                        print(f\"Loaded {count} samples\")\n","                else:\n","                    print(f\"Invalid shape {features.shape} for {feature_path}\")\n","\n","    if not X:\n","        raise ValueError(\"No valid data loaded\")\n","\n","    X = np.array(X)  # Shape: (n_samples, 30, 132)\n","    y = np.array(y)  # Shape: (n_samples,)\n","\n","    # Encode labels\n","    label_encoder = LabelEncoder()\n","    y_encoded = label_encoder.fit_transform(y)\n","    y_onehot = tf.keras.utils.to_categorical(y_encoded)  # Shape: (n_samples, n_classes)\n","\n","    print(f\"Loaded {len(X)} samples with {len(label_encoder.classes_)} classes\")\n","    return X, y_onehot, y_encoded, label_encoder\n","\n","def build_lstm_model(input_shape, num_classes):\n","    \"\"\"Build LSTM model for sign language word recognition.\"\"\"\n","    model = Sequential([\n","        LSTM(256, input_shape=input_shape, return_sequences=True),\n","        Dropout(0.3),\n","        LSTM(128),\n","        Dropout(0.3),\n","        BatchNormalization(),\n","        Dense(128, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n","        Dropout(0.3),\n","        Dense(num_classes, activation='softmax')\n","    ])\n","    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","    return model\n","\n","def plot_training_history(history):\n","    \"\"\"Plot training and validation loss/accuracy.\"\"\"\n","    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n","\n","    ax1.plot(history.history['loss'], label='Train Loss')\n","    ax1.plot(history.history['val_loss'], label='Validation Loss')\n","    ax1.set_title('Model Loss')\n","    ax1.set_xlabel('Epoch')\n","    ax1.set_ylabel('Loss')\n","    ax1.legend()\n","\n","    ax2.plot(history.history['accuracy'], label='Train Accuracy')\n","    ax2.plot(history.history['val_accuracy'], label='Validation Accuracy')\n","    ax2.set_title('Model Accuracy')\n","    ax2.set_xlabel('Epoch')\n","    ax2.set_ylabel('Accuracy')\n","    ax2.legend()\n","\n","    plt.tight_layout()\n","    plt.savefig(os.path.join(EVALUATION_DIR, 'training_history.png'))\n","    plt.close()\n","\n","def plot_confusion_matrix(y_true, y_pred, label_encoder):\n","    \"\"\"Plot confusion matrix.\"\"\"\n","    cm = confusion_matrix(y_true, y_pred)\n","    plt.figure(figsize=(12, 10))\n","    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)\n","    plt.title('Confusion Matrix - LSTM')\n","    plt.xlabel('Predicted')\n","    plt.ylabel('True')\n","    plt.savefig(os.path.join(EVALUATION_DIR, 'confusion_matrix.png'))\n","    plt.close()\n","\n","def train_and_evaluate():\n","    \"\"\"Train and evaluate LSTM model.\"\"\"\n","    # Load data\n","    try:\n","        X, y_onehot, y_encoded, label_encoder = load_data(samples_per_label=30)\n","    except Exception as e:\n","        print(f\"Error loading data: {e}\")\n","        return\n","\n","    # Split train/test\n","    X_train, X_test, y_train, y_test, y_train_encoded, y_test_encoded = train_test_split(\n","        X, y_onehot, y_encoded, test_size=0.2, random_state=42, stratify=y_onehot\n","    )\n","    print(f\"Train: {len(X_train)}, Test: {len(X_test)}\")\n","\n","    # Build model\n","    lstm_model = build_lstm_model(input_shape=(30, 132), num_classes=len(label_encoder.classes_))\n","    lstm_model.summary()\n","\n","    # Callbacks\n","    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n","    checkpoint = ModelCheckpoint(\n","        os.path.join(MODEL_DIR, 'best_lstm_model.h5'), save_best_only=True, monitor='val_loss'\n","    )\n","\n","    # Train\n","    history = lstm_model.fit(\n","        X_train, y_train,\n","        validation_data=(X_test, y_test),\n","        epochs=50,\n","        batch_size=32,\n","        callbacks=[early_stopping, checkpoint],\n","        verbose=1\n","    )\n","\n","    # Evaluate\n","    test_loss, test_accuracy = lstm_model.evaluate(X_test, y_test, verbose=0)\n","    print(f\"\\nTest Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\")\n","\n","    # Predict\n","    y_pred = lstm_model.predict(X_test)\n","    y_pred_classes = np.argmax(y_pred, axis=1)\n","    y_true_classes = np.argmax(y_test, axis=1)\n","\n","    # Compute ROC-AUC\n","    roc_auc = roc_auc_score(y_test, y_pred, multi_class='ovr')\n","    print(f\"ROC-AUC (One-vs-Rest): {roc_auc:.4f}\")\n","\n","    # Save evaluation results\n","    with open(os.path.join(EVALUATION_DIR, 'evaluation_metrics.txt'), 'w') as f:\n","        f.write(f\"Test Loss: {test_loss:.4f}\\n\")\n","        f.write(f\"Test Accuracy: {test_accuracy:.4f}\\n\")\n","        f.write(f\"ROC-AUC (One-vs-Rest): {roc_auc:.4f}\\n\\n\")\n","        f.write(\"Classification Report:\\n\")\n","        f.write(classification_report(y_true_classes, y_pred_classes, target_names=label_encoder.classes_))\n","\n","    # Plot\n","    plot_training_history(history)\n","    plot_confusion_matrix(y_true_classes, y_pred_classes, label_encoder)\n","\n","train_and_evaluate()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"_M7SCmsl6UmF","executionInfo":{"status":"ok","timestamp":1748170740383,"user_tz":-420,"elapsed":1251640,"user":{"displayName":"Anh Hùng Hoàng","userId":"02884634796613907310"}},"outputId":"6d266011-84a0-4324-ab62-fd99bd435a51"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 66 labels: ['anh_huong' 'bac_si' 'bang_bo' 'bao_nhieu' 'bat_nat' 'benh' 'benh_vien'\n"," 'bi_dong' 'binh_thuong' 'bong' 'buoi_chieu' 'buoi_sang' 'buoi_toi'\n"," 'buoi_trua' 'cam' 'cam_on' 'cat' 'cau_cuu' 'cham_soc_suc_khoe' 'chat_doc'\n"," 'chet' 'chua_benh' 'co_don' 'cuop' 'dau_bung' 'dau_chan' 'dau_mat'\n"," 'dau_tai' 'dau_tay' 'di_lac' 'di_ve_sinh' 'dia_chi' 'dien_thoai'\n"," 'don_cong_an' 'dong_y' 'dung_lai' 'gio' 'giup_do' 'hai_long' 'kham_benh'\n"," 'khat_nuoc' 'kho_tieu' 'khong_hieu' 'kiem_tra' 'lay_benh' 'mat_ngu'\n"," 'met_moi' 'muon' 'ngo_doc' 'nguoi_la' 'nguy_hiem' 'nhu cau' 'quen' 'sot'\n"," 'thuc_an' 'thuoc_bo' 'tien' 'toi' 'tranh_thai' 'va_cham'\n"," 've_sinh_ca_nhan' 'xam_hai_tinh_duc' 'xe_cuu_thuong' 'xin_loi' 'y_ta'\n"," 'yeu_cau']\n","Loaded 100 samples\n","Loaded 200 samples\n","Loaded 300 samples\n","Loaded 400 samples\n","Loaded 500 samples\n","Loaded 600 samples\n","Loaded 700 samples\n","Loaded 800 samples\n","Loaded 900 samples\n","Loaded 1000 samples\n","Loaded 1100 samples\n","Loaded 1200 samples\n","Loaded 1300 samples\n","Loaded 1400 samples\n","Loaded 1500 samples\n","Loaded 1600 samples\n","Loaded 1700 samples\n","Loaded 1800 samples\n","Loaded 1900 samples\n","Loaded 2000 samples\n","Loaded 2100 samples\n","Loaded 2200 samples\n","Loaded 2300 samples\n","Loaded 2400 samples\n","Loaded 2500 samples\n","Loaded 2600 samples\n","Loaded 2700 samples\n","Loaded 2800 samples\n","Loaded 2900 samples\n","Loaded 3000 samples\n","Loaded 3100 samples\n","Loaded 3200 samples\n","Loaded 3300 samples\n","Loaded 3400 samples\n","Loaded 3500 samples\n","Loaded 3600 samples\n","Loaded 3700 samples\n","Loaded 3800 samples\n","Loaded 3900 samples\n","Loaded 4000 samples\n","Loaded 4100 samples\n","Loaded 4200 samples\n","Loaded 4300 samples\n","Loaded 4400 samples\n","Loaded 4500 samples\n","Loaded 4600 samples\n","Loaded 4700 samples\n","Loaded 4800 samples\n","Loaded 4900 samples\n","Loaded 5000 samples\n","Loaded 5100 samples\n","Loaded 5200 samples\n","Loaded 5300 samples\n","Loaded 5400 samples\n","Loaded 5500 samples\n","Loaded 5600 samples\n","Loaded 5700 samples\n","Loaded 5800 samples\n","Loaded 5900 samples\n","Loaded 5940 samples with 66 classes\n","Train: 4752, Test: 1188\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(**kwargs)\n"]},{"output_type":"display_data","data":{"text/plain":["\u001b[1mModel: \"sequential_3\"\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n","│ lstm_6 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │       \u001b[38;5;34m398,336\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout_9 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ lstm_7 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m197,120\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout_10 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n","│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m16,512\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout_11 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m66\u001b[0m)             │         \u001b[38;5;34m8,514\u001b[0m │\n","└─────────────────────────────────┴────────────────────────┴───────────────┘\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n","│ lstm_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">398,336</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ lstm_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">197,120</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">66</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,514</span> │\n","└─────────────────────────────────┴────────────────────────┴───────────────┘\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m620,994\u001b[0m (2.37 MB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">620,994</span> (2.37 MB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m620,738\u001b[0m (2.37 MB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">620,738</span> (2.37 MB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m256\u001b[0m (1.00 KB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> (1.00 KB)\n","</pre>\n"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - accuracy: 0.1958 - loss: 4.5745"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 235ms/step - accuracy: 0.1969 - loss: 4.5683 - val_accuracy: 0.7374 - val_loss: 2.9668\n","Epoch 2/50\n","\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.7130 - loss: 1.9622"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 231ms/step - accuracy: 0.7133 - loss: 1.9608 - val_accuracy: 0.8763 - val_loss: 1.2650\n","Epoch 3/50\n","\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step - accuracy: 0.8519 - loss: 1.2264"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 240ms/step - accuracy: 0.8519 - loss: 1.2259 - val_accuracy: 0.9125 - val_loss: 0.8204\n","Epoch 4/50\n","\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224ms/step - accuracy: 0.8944 - loss: 0.8879"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 244ms/step - accuracy: 0.8945 - loss: 0.8874 - val_accuracy: 0.9335 - val_loss: 0.5745\n","Epoch 5/50\n","\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.9283 - loss: 0.6746"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 231ms/step - accuracy: 0.9283 - loss: 0.6745 - val_accuracy: 0.9251 - val_loss: 0.5251\n","Epoch 6/50\n","\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.9528 - loss: 0.5135"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 229ms/step - accuracy: 0.9527 - loss: 0.5136 - val_accuracy: 0.9226 - val_loss: 0.4977\n","Epoch 7/50\n","\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216ms/step - accuracy: 0.9388 - loss: 0.4898"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 238ms/step - accuracy: 0.9389 - loss: 0.4895 - val_accuracy: 0.9411 - val_loss: 0.3947\n","Epoch 8/50\n","\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224ms/step - accuracy: 0.9479 - loss: 0.4057"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 244ms/step - accuracy: 0.9480 - loss: 0.4055 - val_accuracy: 0.9680 - val_loss: 0.2900\n","Epoch 9/50\n","\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.9575 - loss: 0.3567"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 234ms/step - accuracy: 0.9575 - loss: 0.3568 - val_accuracy: 0.9731 - val_loss: 0.2605\n","Epoch 10/50\n","\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 0.9669 - loss: 0.3069"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 229ms/step - accuracy: 0.9669 - loss: 0.3068 - val_accuracy: 0.9739 - val_loss: 0.2231\n","Epoch 11/50\n","\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - accuracy: 0.9768 - loss: 0.2558"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 240ms/step - accuracy: 0.9768 - loss: 0.2558 - val_accuracy: 0.9815 - val_loss: 0.1858\n","Epoch 12/50\n","\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 231ms/step - accuracy: 0.9858 - loss: 0.2086 - val_accuracy: 0.9705 - val_loss: 0.1982\n","Epoch 13/50\n","\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 245ms/step - accuracy: 0.9827 - loss: 0.2185 - val_accuracy: 0.9621 - val_loss: 0.2344\n","Epoch 14/50\n","\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 221ms/step - accuracy: 0.9736 - loss: 0.2374 - val_accuracy: 0.9537 - val_loss: 0.2615\n","Epoch 15/50\n","\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 223ms/step - accuracy: 0.9663 - loss: 0.2585 - val_accuracy: 0.9689 - val_loss: 0.2288\n","Epoch 16/50\n","\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.9781 - loss: 0.2040"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 234ms/step - accuracy: 0.9781 - loss: 0.2040 - val_accuracy: 0.9731 - val_loss: 0.1845\n","Epoch 17/50\n","\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 223ms/step - accuracy: 0.9826 - loss: 0.1888 - val_accuracy: 0.9604 - val_loss: 0.2095\n","Epoch 18/50\n","\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 225ms/step - accuracy: 0.9687 - loss: 0.2271 - val_accuracy: 0.9697 - val_loss: 0.2141\n","Epoch 19/50\n","\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 222ms/step - accuracy: 0.9733 - loss: 0.2169 - val_accuracy: 0.9697 - val_loss: 0.1890\n","Epoch 20/50\n","\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - accuracy: 0.9894 - loss: 0.1383"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 222ms/step - accuracy: 0.9894 - loss: 0.1383 - val_accuracy: 0.9874 - val_loss: 0.1212\n","Epoch 21/50\n","\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.9951 - loss: 0.1119"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 229ms/step - accuracy: 0.9951 - loss: 0.1119 - val_accuracy: 0.9949 - val_loss: 0.0905\n","Epoch 22/50\n","\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 228ms/step - accuracy: 0.9869 - loss: 0.1220 - val_accuracy: 0.9815 - val_loss: 0.1312\n","Epoch 23/50\n","\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 226ms/step - accuracy: 0.9766 - loss: 0.1734 - val_accuracy: 0.9764 - val_loss: 0.1513\n","Epoch 24/50\n","\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 235ms/step - accuracy: 0.9822 - loss: 0.1524 - val_accuracy: 0.9790 - val_loss: 0.1533\n","Epoch 25/50\n","\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 223ms/step - accuracy: 0.9912 - loss: 0.1186 - val_accuracy: 0.9899 - val_loss: 0.1026\n","Epoch 26/50\n","\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 223ms/step - accuracy: 0.9796 - loss: 0.1480 - val_accuracy: 0.9823 - val_loss: 0.1179\n","Epoch 27/50\n","\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 230ms/step - accuracy: 0.9837 - loss: 0.1445 - val_accuracy: 0.9832 - val_loss: 0.1450\n","Epoch 28/50\n","\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 240ms/step - accuracy: 0.9889 - loss: 0.1161 - val_accuracy: 0.9790 - val_loss: 0.1374\n","Epoch 29/50\n","\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 232ms/step - accuracy: 0.9702 - loss: 0.1811 - val_accuracy: 0.9764 - val_loss: 0.1489\n","Epoch 30/50\n","\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 232ms/step - accuracy: 0.9854 - loss: 0.1379 - val_accuracy: 0.9840 - val_loss: 0.1109\n","Epoch 31/50\n","\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 227ms/step - accuracy: 0.9956 - loss: 0.0901 - val_accuracy: 0.9848 - val_loss: 0.1058\n","\n","Test Loss: 0.0905, Test Accuracy: 0.9949\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 68ms/step\n","ROC-AUC (One-vs-Rest): 1.0000\n"]}]}]}